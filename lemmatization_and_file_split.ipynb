{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\den_v\\desktop\\dp_work\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/294.9 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 112.6/294.9 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 245.8/294.9 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.9/294.9 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pymorphy3\n",
    "!pip install scipy==1.12\n",
    "!pip install gensim\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install pyLDAvis\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Лемматизация</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\den_v\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-–»….“«]+\"\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        if token:\n",
    "            token_before = token.strip()\n",
    "            token = morph.normal_forms(token_before)[0]\n",
    "            \n",
    "            tokens.append(token)\n",
    "    if len(tokens) > 2:\n",
    "        return tokens\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n"
     ]
    }
   ],
   "source": [
    "list_of_dreams = []\n",
    "list_of_dreams_lemmatized = []\n",
    "\n",
    "# пример для fiction.txt, но работает и для oral.txt\n",
    "with open(\"fiction.txt\", \"r\", encoding='utf-8') as corp_str:\n",
    "    for line in corp_str:\n",
    "        list_of_dreams.append(line)\n",
    "        lm = lemmatize(line)\n",
    "        lemmatized_line = ' '.join(lm)\n",
    "        list_of_dreams_lemmatized.append(lemmatized_line)\n",
    "    \n",
    "print(len(list_of_dreams), len(list_of_dreams_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Примеры того, что получилось</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мне даже как-то приснился скелет, понимаете, пористый скелет, который всасывает в себя тело; от него, от тела, осталась только липкая какая-то перепонка, но ненасытный скелет засасывает и её; а сам он, заглотавший тело, разбух, раскостился и из белого стал розовато-красным и широкопорым, гадость такая.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_dreams[78]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я даже как то присниться скелет понимать пористый скелет который всасывать в себя тело от он от тело остаться только липкий какой то перепонка но ненасытный скелет засасывать и её а сам он заглотать тело разбухнуть раскоститься и из белый стать розоватый красный и широкопорый гадость такой'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_dreams_lemmatized[78]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Пишем в файл</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример для fiction.txt, но работает и для oral.txt\n",
    "with open('fiction_lemmatized.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(list_of_dreams_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Разбиение на файлы</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_of_dreams_lemmatized)): # разделенные файлы будут в папке oral_splitted/oral_lemmatized\n",
    "    with open(f'oral_splitted/oral_lemmatized/{i+1}_oral_lemmatized.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(list_of_dreams_lemmatized[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_of_dreams_lemmatized)): # разделенные файлы будут в папке fiction_splitted/fiction_lemmatized\n",
    "    with open(f'fiction_splitted/fiction_lemmatized/{i+1}_fiction_lemmatized.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(list_of_dreams_lemmatized[i])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
